{
  "60": {
    "inputs": {
      "filename_prefix": "Qwen-Image-2512",
      "images": [
        "86:8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Enregistrer Image"
    }
  },
  "91": {
    "inputs": {
      "value": "Photorealistic studio reference image of an adult {{NATION}} {{GENDER}} (25 years old) in underwear, {{DESCRIPTION}}, full-body, standing upright in a natural neutral stance, centered, facing the camera straight-on, arms relaxed at sides, feet parallel, neutral face (no smile, no emotion), looking at the camera, plain neutral gray seamless background, soft even studio lighting, realistic skin texture, realistic anatomy and proportions, sharp focus, high detail, 50mm lens look.\n\n"
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "Prompt"
    }
  },
  "86:39": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Charger VAE"
    }
  },
  "86:38": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Charger CLIP"
    }
  },
  "86:37": {
    "inputs": {
      "unet_name": "qwen_image_2512_fp8_e4m3fn.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Charger Modèle Diffusion"
    }
  },
  "86:3": {
    "inputs": {
      "seed": 203495258957698,
      "steps": 50,
      "cfg": 4,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "86:66",
        0
      ],
      "positive": [
        "86:81",
        0
      ],
      "negative": [
        "86:7",
        0
      ],
      "latent_image": [
        "86:58",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "86:58": {
    "inputs": {
      "width": 928,
      "height": 1664,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "86:81": {
    "inputs": {
      "text": [
        "91",
        0
      ],
      "clip": [
        "86:38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "86:8": {
    "inputs": {
      "samples": [
        "86:3",
        0
      ],
      "vae": [
        "86:39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "86:66": {
    "inputs": {
      "shift": 3.1000000000000005,
      "model": [
        "86:37",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "86:7": {
    "inputs": {
      "text": "低分辨率，低画质，肢体畸形，手指畸形，画面过饱和，蜡像感，人脸无细节，过度光滑，画面具有AI感。构图混乱。文字模糊，扭曲",
      "clip": [
        "86:38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  }
}